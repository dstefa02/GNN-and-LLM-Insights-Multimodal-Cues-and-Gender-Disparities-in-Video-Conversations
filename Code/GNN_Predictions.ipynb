{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c74712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" #CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, LSTM, RNN, GRU, ReLU, Tanh, Sigmoid, CrossEntropyLoss\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, CaptumExplainer, PGExplainer, AttentionExplainer\n",
    "from torch_geometric.nn import global_mean_pool, BatchNorm, global_max_pool, global_add_pool, TopKPooling, SAGPooling\n",
    "\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    #torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "#     os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" #CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deaebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Stored Graphs ###\n",
    "# # Only Vocal Features\n",
    "# graphs_females = torch.load('GNN_data_structure_females_v4_vocal.pt')\n",
    "# graphs_males = torch.load('GNN_data_structure_males_v4_vocal.pt')\n",
    "# # Only Facial Features\n",
    "# graphs_females = torch.load('GNN_data_structure_females_v4_facial.pt')\n",
    "# graphs_males = torch.load('GNN_data_structure_males_v4_facial.pt')\n",
    "# # Only Verbal Features\n",
    "# graphs_females = torch.load('GNN_data_structure_females_v4_verbal.pt')\n",
    "# graphs_males = torch.load('GNN_data_structure_males_v4_verbal.pt')\n",
    "# All Features\n",
    "graphs_females = torch.load('GNN_data_structure_females_v4.pt')\n",
    "graphs_males = torch.load('GNN_data_structure_males_v4.pt')\n",
    "\n",
    "num_features = graphs_females[0].x.shape[-1]\n",
    "\n",
    "### Move to GPU ###\n",
    "batch_females = Batch.from_data_list(graphs_females).to(device)\n",
    "batch_males = Batch.from_data_list(graphs_males).to(device)\n",
    "\n",
    "print('Females:', len(graphs_females))\n",
    "print('Males:', len(graphs_males))\n",
    "print('Total:', len(graphs_females)+len(graphs_males))\n",
    "print(len(batch_females.x))\n",
    "print(len(batch_males.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Females ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [150]\n",
    "}\n",
    "best_f1 = 0.0\n",
    "best_params = None\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_females.cpu(), batch_females.y):\n",
    "                train_batch = Batch.from_data_list([graphs_females[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_females[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                pred2 = eval_model(model, test_batch)\n",
    "                \n",
    "                acc_list.append(accuracy_score(y_true=test_batch.y.tolist(), y_pred=pred))\n",
    "                prec_list.append(precision_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                recall_list.append(recall_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                f1_list.append(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                \n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred2, average='macro'))\n",
    "            \n",
    "            print(f1_list)\n",
    "            # print(f'    Females Accuracy score: {sum(all_acc_list)/len(all_acc_list):.4f}')\n",
    "            print(hidden_channels, epochs)\n",
    "            print(f'    Females Precision: {np.mean(prec_list):.2f} ± {np.std(prec_list):.2f}')\n",
    "            print(f'    Females Recall   : {np.mean(recall_list):.2f} ± {np.std(recall_list):.2f}')\n",
    "            print(f'    Females F1       : {np.mean(f1_list):.2f} ± {np.std(f1_list):.2f}')\n",
    "            print('-'*50)\n",
    "\n",
    "            # Check if the current hyperparameters are the best so far\n",
    "            f1 = sum(f1_list)/len(f1_list)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\"hidden_channels\": hidden_channels, \"epochs\": epochs}\n",
    "# print('='*100)\n",
    "# print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "# print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.08)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Males ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [240]\n",
    "}\n",
    "best_f1 = 0.0\n",
    "best_params = None\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_males.cpu(), batch_males.y):\n",
    "                train_batch = Batch.from_data_list([graphs_males[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_males[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                pred2 = eval_model(model, test_batch)\n",
    "                \n",
    "                acc_list.append(accuracy_score(y_true=test_batch.y.tolist(), y_pred=pred))\n",
    "                prec_list.append(precision_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                recall_list.append(recall_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                f1_list.append(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                \n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred2, average='macro'))\n",
    "            \n",
    "            print(f1_list)\n",
    "            # print(f'    Females Accuracy score: {sum(all_acc_list)/len(all_acc_list):.4f}')\n",
    "            print(hidden_channels, epochs)\n",
    "            print(f'    Males Precision: {np.mean(prec_list):.2f} ± {np.std(prec_list):.2f}')\n",
    "            print(f'    Males Recall   : {np.mean(recall_list):.2f} ± {np.std(recall_list):.2f}')\n",
    "            print(f'    Males F1       : {np.mean(f1_list):.2f} ± {np.std(f1_list):.2f}')\n",
    "            print('-'*50)\n",
    "\n",
    "            # Check if the current hyperparameters are the best so far\n",
    "            f1 = sum(f1_list)/len(f1_list)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\"hidden_channels\": hidden_channels, \"epochs\": epochs}\n",
    "# print('='*100)\n",
    "# print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "# print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3ed12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f37f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Different Layers of GCN to compare ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4574de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.conv3 = GCNConv(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.conv4 = GCNConv(int(hidden_channels/4), num_classes)\n",
    "#         self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "#         self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "#         x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Females ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [150]\n",
    "}\n",
    "best_f1 = 0.0\n",
    "best_params = None\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_females.cpu(), batch_females.y):\n",
    "                train_batch = Batch.from_data_list([graphs_females[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_females[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                pred2 = eval_model(model, test_batch)\n",
    "                \n",
    "                acc_list.append(accuracy_score(y_true=test_batch.y.tolist(), y_pred=pred))\n",
    "                prec_list.append(precision_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                recall_list.append(recall_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                f1_list.append(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                \n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred2, average='macro'))\n",
    "            \n",
    "            print(f1_list)\n",
    "            # print(f'    Females Accuracy score: {sum(all_acc_list)/len(all_acc_list):.4f}')\n",
    "            print(hidden_channels, epochs)\n",
    "            print(f'    Females Precision: {np.mean(prec_list):.2f} ± {np.std(prec_list):.2f}')\n",
    "            print(f'    Females Recall   : {np.mean(recall_list):.2f} ± {np.std(recall_list):.2f}')\n",
    "            print(f'    Females F1       : {np.mean(f1_list):.2f} ± {np.std(f1_list):.2f}')\n",
    "            print('-'*50)\n",
    "\n",
    "            # Check if the current hyperparameters are the best so far\n",
    "            f1 = sum(f1_list)/len(f1_list)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\"hidden_channels\": hidden_channels, \"epochs\": epochs}\n",
    "# print('='*100)\n",
    "# print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "# print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e585f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.conv3 = GCNConv(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.conv4 = GCNConv(int(hidden_channels/4), num_classes)\n",
    "#         self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "#         self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.conv4(x, edge_index)\n",
    "#         x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.08)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Males ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [240]\n",
    "}\n",
    "best_f1 = 0.0\n",
    "best_params = None\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_males.cpu(), batch_males.y):\n",
    "                train_batch = Batch.from_data_list([graphs_males[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_males[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                pred2 = eval_model(model, test_batch)\n",
    "                \n",
    "                acc_list.append(accuracy_score(y_true=test_batch.y.tolist(), y_pred=pred))\n",
    "                prec_list.append(precision_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                recall_list.append(recall_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                f1_list.append(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                \n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred, average='macro'))\n",
    "                #print(f1_score(y_true=test_batch.y.tolist(), y_pred=pred2, average='macro'))\n",
    "            \n",
    "            print(f1_list)\n",
    "            # print(f'    Females Accuracy score: {sum(all_acc_list)/len(all_acc_list):.4f}')\n",
    "            print(hidden_channels, epochs)\n",
    "            print(f'    Males Precision: {np.mean(prec_list):.2f} ± {np.std(prec_list):.2f}')\n",
    "            print(f'    Males Recall   : {np.mean(recall_list):.2f} ± {np.std(recall_list):.2f}')\n",
    "            print(f'    Males F1       : {np.mean(f1_list):.2f} ± {np.std(f1_list):.2f}')\n",
    "            print('-'*50)\n",
    "\n",
    "            # Check if the current hyperparameters are the best so far\n",
    "            f1 = sum(f1_list)/len(f1_list)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\"hidden_channels\": hidden_channels, \"epochs\": epochs}\n",
    "# print('='*100)\n",
    "# print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "# print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde80cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export Prediction of model and test for gender bias ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Females ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [150]\n",
    "}\n",
    "print(\"prediction,isFemale\")\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_females.cpu(), batch_females.y):\n",
    "                train_batch = Batch.from_data_list([graphs_females[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_females[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                \n",
    "                for i in range(0, len(pred)):\n",
    "                    print(str(pred[i]) + \",\" + \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "from torch_geometric.nn import GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "from torch.optim import SGD\n",
    "import torch.nn.init as init\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.08)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred\n",
    "\n",
    "### Train and Evaluate Model (Stratified K-Fold) ###\n",
    "print('Train and Evaluate Model (Stratified K-Fold)...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "num_folds = 5 # Define the number of folds\n",
    "\n",
    "######################################################\n",
    "### Males ###\n",
    "######################################################\n",
    "params = {\n",
    "    \"hidden_channels\": [128],\n",
    "    \"epochs\": [240]\n",
    "}\n",
    "best_f1 = 0.0\n",
    "best_params = None\n",
    "print(\"prediction,isFemale\")\n",
    "\n",
    "for seed in range(0, 1):\n",
    "    # Create a KFold object\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_channels in params[\"hidden_channels\"]:\n",
    "        for epochs in params[\"epochs\"]:\n",
    "            acc_list, prec_list, recall_list, f1_list = [], [], [], []\n",
    "\n",
    "            # Use the KFold object to split the data into train and test sets\n",
    "            for train_index, test_index in skf.split(batch_males.cpu(), batch_males.y):\n",
    "                train_batch = Batch.from_data_list([graphs_males[i] for i in train_index]).to(device)\n",
    "                test_batch = Batch.from_data_list([graphs_males[i] for i in test_index]).to(device)\n",
    "                \n",
    "                model = train_model(num_features, hidden_channels, epochs, train_batch)\n",
    "                pred = eval_model(model, test_batch)\n",
    "                for i in range(0, len(pred)):\n",
    "                    print(str(pred[i]) + \",\" + \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f7b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

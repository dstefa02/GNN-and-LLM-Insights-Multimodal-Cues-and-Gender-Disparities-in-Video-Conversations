{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e79436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install numpy\n",
    "# # !pip install Pillow\n",
    "# # !pip install requests\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow[and-cuda]\n",
    "# !pip list | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8229179",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries ###\n",
    "import os, sys, re, time, json, traceback, logging, datetime, gc, shutil, math, base64, pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# import torch\n",
    "# from numba import cuda\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "### Image Libraries ###\n",
    "# import tensorflow as tf\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# if tf.test.gpu_device_name():\n",
    "#     print('GPU found')\n",
    "# else:\n",
    "#     print(\"No GPU found\")\n",
    "import cv2\n",
    "import moviepy.editor\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "from deepface.detectors import FaceDetector\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57db005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.current_device())\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.version.cuda)\n",
    "# print(torch.backends.cudnn.version())\n",
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Path of Files ###\n",
    "input_video_filename_wo_ext = '1_min_video'\n",
    "input_video_filename = 'Videos_Examples/'+ input_video_filename_wo_ext +'.mp4' # The video files should be on mp4 format\n",
    "output_video_path = 'Videos_Output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory of output of videos\n",
    "if not os.path.exists(output_video_path):\n",
    "    os.makedirs(output_video_path)\n",
    "\n",
    "# Create a new directory for processed audio if it does not exist\n",
    "dir_output_audio = output_video_path + input_video_filename_wo_ext +'/Audio/'\n",
    "if not os.path.exists(dir_output_audio):\n",
    "    os.makedirs(dir_output_audio)\n",
    "dir_output_audio_step1 = output_video_path + input_video_filename_wo_ext +'/Audio/Step1_ProcessAudio/'\n",
    "if not os.path.exists(dir_output_audio_step1):\n",
    "    os.makedirs(dir_output_audio_step1)\n",
    "dir_output_audio_step2 = output_video_path + input_video_filename_wo_ext +'/Audio/Step2_Spleeter/'\n",
    "if not os.path.exists(dir_output_audio_step2):\n",
    "    os.makedirs(dir_output_audio_step2)\n",
    "dir_output_audio_step3 = output_video_path + input_video_filename_wo_ext +'/Audio/Step3_Segments/'\n",
    "if not os.path.exists(dir_output_audio_step3):\n",
    "    os.makedirs(dir_output_audio_step3)\n",
    "dir_output_audio_step4 = output_video_path + input_video_filename_wo_ext +'/Audio/Step4_Embeddings/'\n",
    "if not os.path.exists(dir_output_audio_step4):\n",
    "    os.makedirs(dir_output_audio_step4)\n",
    "dir_output_audio_step5 = output_video_path + input_video_filename_wo_ext +'/Audio/Step5_Clusters/'\n",
    "if not os.path.exists(dir_output_audio_step5):\n",
    "    os.makedirs(dir_output_audio_step5)\n",
    "    \n",
    "# Create a new directory for processed images if it does not exist\n",
    "dir_output_images = output_video_path + input_video_filename_wo_ext +'/Images/'\n",
    "if not os.path.exists(dir_output_images):\n",
    "    os.makedirs(dir_output_images)\n",
    "dir_output_images_step1 = output_video_path + input_video_filename_wo_ext +'/Images/Step1_Images/'\n",
    "if not os.path.exists(dir_output_images_step1):\n",
    "    os.makedirs(dir_output_images_step1)\n",
    "dir_output_images_step2 = output_video_path + input_video_filename_wo_ext +'/Images/Step2_Faces/'\n",
    "if not os.path.exists(dir_output_images_step2):\n",
    "    os.makedirs(dir_output_images_step2)\n",
    "dir_output_images_step3 = output_video_path + input_video_filename_wo_ext +'/Images/Step3_Embeddings/'\n",
    "if not os.path.exists(dir_output_images_step3):\n",
    "    os.makedirs(dir_output_images_step3)\n",
    "dir_output_images_step4 = output_video_path + input_video_filename_wo_ext +'/Images/Step4_Clusters/'\n",
    "if not os.path.exists(dir_output_images_step4):\n",
    "    os.makedirs(dir_output_images_step4)\n",
    "\n",
    "# Create a new directory for processed text if it does not exist\n",
    "dir_output_text = output_video_path + input_video_filename_wo_ext +'/Text/'\n",
    "if not os.path.exists(dir_output_text):\n",
    "    os.makedirs(dir_output_text)\n",
    "dir_output_text_seg = output_video_path + input_video_filename_wo_ext +'/Text/Segments/'\n",
    "if not os.path.exists(dir_output_text_seg):\n",
    "    os.makedirs(dir_output_text_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Video to Image\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "### Extract Frames from Videos ###\n",
    "fields = input_video_filename.split('.mp4')\n",
    "\n",
    "input_movie = cv2.VideoCapture(input_video_filename)\n",
    "total_frames = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(input_movie.get(cv2.CAP_PROP_FPS))\n",
    "video_duration_sec = int(total_frames/fps)\n",
    "duration = input_movie.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "video = moviepy.editor.VideoFileClip(input_video_filename)\n",
    "video_duration = int(video.duration)\n",
    "\n",
    "# Initialize variables\n",
    "frame_number = 0\n",
    "frame_counter = 0\n",
    "CONST_FPS_KEEP = 1\n",
    "constant_incr = int(fps/CONST_FPS_KEEP)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = input_movie.read()\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Quit when the input video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imwrite(dir_output_images_step1 + \"frame_%d.jpg\" % (frame_counter), frame)\n",
    "    frame_number += constant_incr\n",
    "    input_movie.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "# print('Stored frame counter:', frame_counter)\n",
    "# print('Total frames:', total_frames)\n",
    "# print('video_duration:', video_duration, '\\n')\n",
    "\n",
    "# input_movie.release()\n",
    "# cv2.destroyAllWindows()\n",
    "input_movie.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_name = 'mtcnn'\n",
    "detector = FaceDetector.build_model(detector_name) # set opencv, ssd, dlib, mtcnn or retinaface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081baeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(dir_output_images_step1+'frame_1.jpg')\n",
    "# faces_obj = FaceDetector.detect_faces(detector, detector_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detected_and_aligned_face = DeepFace.extract_faces(dir_output_images_step1+'frame_1.jpg', detector_backend = 'retinaface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96274fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Recognize Faces ###\n",
    "# Face Detectors\n",
    "# detector_name = 'mtcnn'\n",
    "# detector = FaceDetector.build_model(detector_name) # set opencv, ssd, dlib, mtcnn or retinaface\n",
    "\n",
    "i = 0\n",
    "sorted_files = sorted(os.listdir(dir_output_images_step1))\n",
    "for filename in sorted_files:\n",
    "    \n",
    "    s_e_p = filename.split('_')[0]\n",
    "\n",
    "    img = cv2.imread(dir_output_images_step1+filename)\n",
    "    faces_obj = FaceDetector.detect_faces(detector, detector_name, img)\n",
    "    \n",
    "    \n",
    "    for detected_face, region, score in faces_obj:\n",
    "        height, width = len(detected_face), len(detected_face[0])\n",
    "        \n",
    "        # Export facial image only if image size is between [48*48, 4096*4096] (pixels)\n",
    "        # (Face++ documentation: https://console.faceplusplus.com/documents)\n",
    "        if height >= 48 and width >= 48:\n",
    "            cv2.imwrite(dir_output_images_step2+'face_%d.jpg' % (i), detected_face)\n",
    "            #print(dir_output_images_step2+'face_%d.jpg' % (i))\n",
    "            i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# detector = None\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Create Face Embeddings ###\n",
    "# if not os.path.exists(dir_output_images_step3 + 'embeddings.pkl'): # Create embeddings\n",
    "embeddings = []\n",
    "embeddings_filename = []\n",
    "\n",
    "for filename in sorted(os.listdir(dir_output_images_step2)):\n",
    "    if '.jpg' in filename:\n",
    "        embeddings.append(DeepFace.represent(dir_output_images_step2+filename, enforce_detection=False)[0]['embedding'])\n",
    "        embeddings_filename.append(filename)\n",
    "\n",
    "# Store pickle/embeddings\n",
    "embeddings_all = {'embeddings': embeddings, 'filename': embeddings_filename}\n",
    "\n",
    "f_pickle = open(dir_output_images_step3 + 'embeddings.pkl', \"wb\")\n",
    "pickle.dump(embeddings_all, f_pickle)\n",
    "f_pickle.close()\n",
    "# else: # Read pickle/embeddings\n",
    "#     f_pickle = open(dir_output_images_step3 + 'embeddings.pkl', 'rb')\n",
    "#     embeddings_all = pickle.load(f_pickle)\n",
    "#     f_pickle.close()\n",
    "\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pickle = open(dir_output_images_step3 + 'embeddings.pkl', 'rb')\n",
    "embeddings_all = pickle.load(f_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "### Cluster Face Embeddings ###\n",
    "# Delete all clusters folders\n",
    "for filename in sorted(os.listdir(dir_output_images_step4)):\n",
    "    if 'cluster' in filename:\n",
    "        shutil.rmtree(dir_output_images_step4+filename)\n",
    "\n",
    "n_clusters = 7\n",
    "clf = KMeans(n_clusters=n_clusters, n_init=100, max_iter=600, random_state=0)\n",
    "# if kmeans use number of speakers from voice\n",
    "# clf = DBSCAN(n_jobs=-1, eps=0.11, metric='cosine')\n",
    "clf.fit(embeddings_all['embeddings'])\n",
    "preds = clf.labels_\n",
    "\n",
    "for i in range(0, len(preds)):\n",
    "    cluster_dir = 'cluster ' + str(preds[i]) + '/'\n",
    "\n",
    "    if not os.path.exists(dir_output_images_step4 + cluster_dir):\n",
    "        os.makedirs(dir_output_images_step4 + cluster_dir)\n",
    "    shutil.copyfile(dir_output_images_step2 + embeddings_all['filename'][i], dir_output_images_step4 + cluster_dir + '/' + embeddings_all['filename'][i])\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e54c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

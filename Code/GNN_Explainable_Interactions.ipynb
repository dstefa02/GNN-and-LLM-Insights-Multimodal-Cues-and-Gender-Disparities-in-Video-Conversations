{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c74712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" #CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GatedGraphConv, GATConv, SuperGATConv, MLP, GraphSAGE\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, LSTM, RNN, GRU, ReLU, Tanh, Sigmoid, CrossEntropyLoss\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, CaptumExplainer, PGExplainer, AttentionExplainer\n",
    "from torch_geometric.nn import global_mean_pool, BatchNorm, global_max_pool, global_add_pool, TopKPooling, SAGPooling\n",
    "\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    #torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "#     os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" #CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66400a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define GNN model ###\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels/2))\n",
    "        self.linear = Linear(int(hidden_channels/2), int(hidden_channels/4))\n",
    "        self.lstm = LSTM(int(hidden_channels/4), num_classes)\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings: Embed each node by performing multiple rounds of message passing\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        # 2. Readout layer: Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "        x = global_mean_pool(x, batch) #, TopKPooling, SAGPooling# global_mean_pool(x, batch)\n",
    "        # 3. Apply a final classifier: Train a final classifier on the graph embedding\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(num_features, hidden_channels, epochs, train_batch):\n",
    "    # Create an instance of the model\n",
    "    model = GCN(num_features, hidden_channels, 2).to(device)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train Model\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch.x, train_batch.edge_index, train_batch.batch)\n",
    "        loss = criterion(out, train_batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_batch):\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    out = model(test_batch.x, test_batch.edge_index, test_batch.batch)\n",
    "    pred = out.argmax(dim=1).tolist()  # Use the class with highest probability.\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd29ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of features: 55\n",
      "Females: 272\n",
      "Males: 625\n",
      "Total: 897\n",
      "15617\n",
      "32873\n",
      "Females - Train Model for Explainable AI...\n",
      "Finish training model for Females.\n",
      "Males - Train Model for Explainable AI...\n",
      "Finish training model for Males.\n",
      "Explanations Females...\n",
      "Explanations Males...\n",
      "Finish CAPTUM.\n",
      "0.0011335219566611283\n",
      "5.092406211037956e-10\n",
      "-1.34576740555478e-08\n",
      "2.3114518028138525e-08\n",
      "3.240586052366987e-05\n",
      "-9.739542648701068e-07\n",
      "8.510157036602524e-08\n",
      "-0.00029629402103880514\n",
      "-4.849941309369136e-07\n",
      "-1.2134708501712545e-10\n",
      "3.3311856567149174e-05\n",
      "-7.652904136217894e-06\n",
      "3.4809089711530958e-12\n",
      "9.754191845781152e-07\n",
      "-1.176823583468443e-05\n",
      "-0.00017334259400377528\n",
      "0.00023038486479099975\n",
      "2.5471755425702028e-05\n",
      "6.417323518095035e-08\n",
      "0.0\n",
      "4.19439800486183e-06\n",
      "3.473508111734468e-08\n",
      "0.0\n",
      "-2.6486286321586163e-06\n",
      "1.1155886431861712e-06\n",
      "4.260704736946701e-06\n",
      "0.0\n",
      "-4.889449467078517e-08\n",
      "5.334456557315504e-08\n",
      "-6.1421171739795135e-06\n",
      "0.00027376928794986224\n",
      "0.0\n",
      "9.978734490492005e-11\n",
      "-4.494074014222376e-05\n",
      "-2.1872089441555216e-12\n",
      "8.60636853747027e-09\n",
      "0.0\n",
      "1.1231903449795091e-05\n",
      "1.3859740973477298e-06\n",
      "-7.138160462889799e-07\n",
      "9.321303670290942e-06\n",
      "-8.533218017521688e-07\n",
      "1.2350595652999784e-06\n",
      "3.824430376537498e-06\n",
      "1.6480352611172945e-05\n",
      "-7.201914801369811e-08\n",
      "1.3064509562975403e-06\n",
      "-1.7268136755753113e-05\n",
      "6.865632215458651e-05\n",
      "2.597662292946003e-07\n",
      "1.176027397955487e-07\n",
      "8.031634683208763e-10\n",
      "-1.0114092413757886e-06\n",
      "2.43500642055813e-07\n",
      "3.6284582773107504e-10\n",
      "-3.0431099354469703e-06\n",
      "-3.979021278690063e-06\n",
      "-0.0003418167832186345\n",
      "-8.295824707586798e-06\n",
      "-9.240776698065052e-05\n",
      "3.905691567319578e-07\n",
      "2.56578682695793e-07\n",
      "3.2128603472979878e-09\n",
      "2.2885856301796687e-07\n",
      "1.7829574588499082e-07\n",
      "-2.441119118737242e-07\n",
      "1.2827251888109838e-09\n",
      "3.6786327354271223e-08\n",
      "-2.397745572958693e-08\n",
      "-0.0002532786149515666\n",
      "-5.4115027576498025e-06\n",
      "2.427979793784303e-08\n",
      "-6.257354466435415e-06\n",
      "-2.7358731654666596e-05\n",
      "-5.458375915222627e-06\n",
      "3.5587313287510332e-06\n",
      "-2.8054794269240167e-05\n",
      "-1.0819332777300989e-08\n",
      "3.665435625385862e-07\n",
      "7.411129213181743e-07\n",
      "-1.990727873325786e-07\n",
      "-8.16957362911005e-07\n",
      "-9.48332381498302e-07\n",
      "7.70281998651418e-05\n",
      "4.259933524185045e-06\n",
      "1.3489173910894428e-05\n",
      "-3.2177418602592115e-08\n",
      "-1.2799929578237935e-06\n",
      "8.35142983557697e-10\n",
      "2.8385099959028136e-05\n",
      "3.878554761210972e-08\n",
      "1.9811936023272525e-06\n",
      "2.900426166054692e-07\n",
      "6.746184118786713e-05\n",
      "3.5468013208478385e-05\n",
      "8.278411530553777e-05\n",
      "1.8717380466135508e-11\n",
      "1.034933339842514e-05\n",
      "-9.630300102709539e-05\n",
      "1.5796128395731008e-06\n",
      "1.662158853181126e-08\n",
      "5.951272372153417e-05\n",
      "2.1334673177082618e-08\n",
      "2.4530233285279007e-07\n",
      "-0.0008737959319534914\n",
      "1.5316137406773057e-07\n",
      "8.380525644312526e-07\n",
      "6.443380317305225e-09\n",
      "-1.9237979391909207e-08\n",
      "6.404521574571942e-07\n",
      "1.247829550112744e-05\n",
      "1.2592642688401108e-05\n",
      "-3.253173361376829e-07\n",
      "-5.920158680012698e-07\n",
      "2.8445069861501894e-08\n",
      "0.0\n",
      "3.3856072639070295e-13\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.8221423751020574e-06\n",
      "8.890412855615499e-07\n",
      "2.154130225302558e-06\n",
      "-4.1190054436055995e-05\n",
      "3.921985750282202e-06\n",
      "3.9046329448819925e-06\n",
      "-6.046057489502442e-06\n",
      "-3.7764190434995045e-07\n",
      "-1.5728255592249e-07\n",
      "5.983686518355625e-07\n",
      "-1.5557127881390555e-08\n",
      "5.268750957246525e-07\n",
      "6.581316956538811e-08\n",
      "8.415279372833507e-08\n",
      "1.961055376208397e-06\n",
      "7.627516459176666e-12\n",
      "6.771662132213648e-08\n",
      "3.803867055058357e-07\n",
      "4.4792019255830064e-10\n",
      "-4.099847882097867e-08\n",
      "8.123142770424422e-08\n",
      "-4.534825778173108e-06\n",
      "-2.0788257868819066e-06\n",
      "4.698731817261743e-08\n",
      "8.430735492054188e-06\n",
      "-5.180732514930416e-13\n",
      "-2.536268376240312e-07\n",
      "1.956802205728388e-06\n",
      "2.6330317418183033e-11\n",
      "3.8659899726051993e-08\n",
      "7.921843410702747e-14\n",
      "1.0485842281050098e-09\n",
      "-2.53947214806882e-06\n",
      "0.0\n",
      "0.0\n",
      "1.7634686557117754e-06\n",
      "5.682887194717979e-07\n",
      "8.710362268003406e-07\n",
      "2.6048479607373137e-06\n",
      "1.1545914000937314e-09\n",
      "2.074794560577432e-11\n",
      "-2.4165550937520343e-06\n",
      "1.4042225401308855e-05\n",
      "4.459350462022711e-07\n",
      "4.618420983760652e-07\n",
      "-1.481810402147108e-05\n",
      "2.7911622557368e-08\n",
      "1.2257666195133129e-06\n",
      "-4.045011131130808e-08\n",
      "1.898984110820033e-08\n",
      "8.158824795903806e-08\n",
      "-1.4335891410132435e-08\n",
      "1.3221819367167955e-09\n",
      "2.597283395353276e-09\n",
      "1.6041021835010015e-07\n",
      "1.3085430065162642e-06\n",
      "-8.415197843130433e-06\n",
      "2.3834806689630107e-06\n",
      "1.232354031654708e-10\n",
      "2.2868525451006973e-08\n",
      "4.1824726536106014e-07\n",
      "2.4695655519957862e-09\n",
      "3.1524565257825146e-08\n",
      "9.859478477313992e-07\n",
      "2.803118123004811e-07\n",
      "0.00037618466531101776\n",
      "1.867044171293432e-05\n",
      "-3.3348080930769304e-07\n",
      "7.397248218019636e-06\n",
      "9.258850169796534e-08\n",
      "5.654025035023866e-05\n",
      "4.5900200657941145e-07\n",
      "2.342285745454208e-07\n",
      "8.014684706819648e-07\n",
      "0.0\n",
      "-1.4780831248133202e-05\n",
      "2.600356251611945e-09\n",
      "9.718147058313212e-11\n",
      "1.7227883475814536e-09\n",
      "2.3414107551069565e-08\n",
      "9.731564255665626e-07\n",
      "1.2979534771934172e-06\n",
      "7.296518070429172e-07\n",
      "-6.843649814381012e-05\n",
      "0.0032884717684203563\n",
      "-0.0006784630514148092\n",
      "3.7098552997224946e-05\n",
      "0.004998511621696992\n",
      "7.345825280962154e-05\n",
      "2.903375670301946e-10\n",
      "4.679437406861602e-06\n",
      "-5.319922021791684e-05\n",
      "1.3402141145069155e-09\n",
      "-2.1083266466788292e-06\n",
      "1.3361992028727278e-06\n",
      "0.0014911983409761687\n",
      "0.00014047546358638034\n",
      "2.9215844874399374e-07\n",
      "5.519209521546671e-14\n",
      "0.00043774697434695396\n",
      "-1.3122112793368759e-07\n",
      "1.0702055770123199e-07\n",
      "3.6593002720414063e-06\n",
      "-6.077935287395213e-07\n",
      "3.7235817669060104e-05\n",
      "0.00040052723243288004\n",
      "1.287107510671085e-06\n",
      "2.877168317537862e-06\n",
      "5.8471508786221145e-05\n",
      "2.8486172087987964e-06\n",
      "0.0\n",
      "-1.0256147107996959e-07\n",
      "3.270779580859307e-05\n",
      "8.065081837257523e-09\n",
      "4.3406163258203176e-07\n",
      "1.2210979855475912e-05\n",
      "4.851987467599915e-10\n",
      "-1.1530209706789553e-07\n",
      "-3.429429064664545e-07\n",
      "1.7638045086662287e-08\n",
      "3.499030723690999e-10\n",
      "9.946160758066595e-07\n",
      "-1.5027923912585694e-12\n",
      "-1.4539347254576121e-06\n",
      "2.867830001745592e-06\n",
      "9.084090078024556e-08\n",
      "5.576692940893966e-17\n",
      "2.783426308403974e-06\n",
      "7.409081410854533e-06\n",
      "1.3553535946365073e-07\n",
      "6.966475405455679e-09\n",
      "1.122724277544952e-08\n",
      "1.8588027325195307e-14\n",
      "8.501295730009664e-09\n",
      "2.427794401827077e-09\n",
      "9.874713945698566e-10\n",
      "0.000461484222120737\n",
      "3.920933716981006e-08\n",
      "3.8513616381002764e-07\n",
      "2.576795404793478e-11\n",
      "0.0\n",
      "6.29050995163975e-08\n",
      "4.076898487147802e-06\n",
      "3.6678675660100143e-07\n",
      "2.5897588860702553e-05\n",
      "4.641461248807969e-05\n",
      "-7.339835632132648e-10\n",
      "2.2400581565753435e-06\n",
      "-0.0005122066243054094\n",
      "-1.5763874133741724e-11\n",
      "1.9440135364079975e-06\n",
      "7.135991011858787e-05\n",
      "3.270402905055155e-08\n",
      "-0.0010920277322431934\n",
      "-0.00013285845883730444\n",
      "2.1412405194880408e-07\n",
      "-2.3232460036696296e-08\n",
      "3.3526042661110125e-06\n",
      "1.7030920610080112e-06\n",
      "-0.00011819400034427487\n",
      "-1.279079807252423e-08\n",
      "6.1252308153725445e-06\n",
      "6.166274431602255e-05\n",
      "-5.183909001832257e-08\n",
      "2.0364338125776648e-09\n",
      "1.5463742275814328e-06\n",
      "-4.664444581724544e-08\n",
      "8.065732657916506e-06\n",
      "0.00011121540690530243\n",
      "-1.6057170286268947e-08\n",
      "6.178644858510006e-05\n",
      "-1.545417889901934e-07\n",
      "2.33821592533758e-07\n",
      "2.850841046679811e-08\n",
      "-1.0407086170947329e-08\n",
      "-7.6288993494781035e-06\n",
      "0.0006301129542369979\n",
      "-1.974752231661552e-06\n",
      "7.43145026239582e-11\n",
      "4.081313092698725e-05\n",
      "0.00013755920409212814\n",
      "3.9202563604944094e-07\n",
      "1.7915076569832727e-07\n",
      "-3.033144758748391e-08\n",
      "0.0\n",
      "-2.286363872523822e-05\n",
      "-3.350759394475088e-07\n",
      "0.0\n",
      "-1.7852395468483977e-05\n",
      "1.1515838315890307e-07\n",
      "0.00021976741299016618\n",
      "-6.831143636843763e-06\n",
      "2.030660891142408e-09\n",
      "-3.515131764610335e-11\n",
      "-1.0626202371290728e-05\n",
      "0.0007716519052476864\n",
      "0.0\n",
      "1.978115621149449e-06\n",
      "0.0\n",
      "7.919746531280503e-09\n",
      "7.457819508754787e-06\n",
      "5.218335774859273e-09\n",
      "-0.0002447115924309719\n",
      "6.167056423085713e-08\n",
      "-1.209401887343346e-06\n",
      "7.290543211491398e-07\n",
      "0.0013149856773316583\n",
      "0.0\n",
      "3.4038142818811625e-07\n",
      "2.996968807202835e-06\n",
      "9.624168160024152e-07\n",
      "-5.771729805414985e-12\n",
      "0.00010129379471298977\n",
      "2.0371141007547905e-05\n",
      "9.94920710850622e-06\n",
      "-9.333386494795449e-08\n",
      "-1.481440398846017e-09\n",
      "2.9583015803358466e-07\n",
      "3.336718306075365e-06\n",
      "0.0\n",
      "2.579039748286558e-10\n",
      "1.6785526814315509e-12\n",
      "-1.2764140115040753e-08\n",
      "-4.274445978933168e-09\n",
      "5.798540922988024e-09\n",
      "5.298143351286937e-14\n",
      "0.0\n",
      "4.1207829014017237e-07\n",
      "-1.4864615073956996e-07\n",
      "2.063648456818933e-07\n",
      "-4.843555730274314e-05\n",
      "1.167892687453485e-05\n",
      "0.0\n",
      "1.4482241674980987e-09\n",
      "-3.4203138411235915e-08\n",
      "-3.642879396767303e-08\n",
      "-3.922900847655021e-07\n",
      "-8.011225577220877e-09\n",
      "-4.5929976368890957e-10\n",
      "0.0\n",
      "6.626028434555682e-08\n",
      "-6.759770032604102e-05\n",
      "4.1229119073588674e-07\n",
      "9.264854107057313e-08\n",
      "2.815200706600967e-08\n",
      "2.1958971478963704e-06\n",
      "-4.195001259144494e-05\n",
      "9.933813436353673e-05\n",
      "1.9495530944181137e-05\n",
      "1.0734772660336455e-06\n",
      "2.577595785398897e-10\n",
      "-2.0188585121553534e-12\n",
      "-1.9891942001108445e-06\n",
      "5.712751978963037e-06\n",
      "6.112267827871202e-08\n",
      "1.1947434840398e-05\n",
      "-7.253961166216911e-06\n",
      "2.482892836073203e-07\n",
      "-6.517183326357849e-05\n",
      "-0.00011135041474616933\n",
      "7.4402586177527e-05\n",
      "1.7233696288729185e-07\n",
      "0.0\n",
      "3.2429404478164116e-08\n",
      "5.526672217550177e-07\n",
      "-1.757045674300748e-05\n",
      "-1.7202274657428766e-07\n",
      "2.182695768389168e-06\n",
      "0.0\n",
      "-1.0451232352902505e-06\n",
      "-1.729531252569845e-06\n",
      "-0.0013820111311652714\n",
      "-2.166564859557669e-07\n",
      "4.3996351491507004e-07\n",
      "1.0245873447687154e-06\n",
      "4.387115738046002e-07\n",
      "-9.16184240580893e-07\n",
      "0.0\n",
      "2.514363827479578e-11\n",
      "2.264459921909898e-07\n",
      "3.5563538723140995e-07\n",
      "-1.7388919005430662e-07\n",
      "2.270930218243064e-07\n",
      "-9.978647059255258e-08\n",
      "4.538941963509093e-07\n",
      "8.144248694207809e-06\n",
      "0.0007497107687285131\n",
      "4.299343706089481e-06\n",
      "-1.5488058185009093e-08\n",
      "6.036694762799096e-06\n",
      "-3.5819470388983506e-06\n",
      "1.1204853570236977e-06\n",
      "0.0006227393890446025\n",
      "-9.792021323482915e-06\n",
      "9.79300187176638e-07\n",
      "5.053456517264554e-06\n",
      "-2.583364726298985e-06\n",
      "-4.6516031333498457e-10\n",
      "0.00010720871359793296\n",
      "4.957570604369491e-06\n",
      "0.0\n",
      "1.3632341389709509e-12\n",
      "-1.2064626449275788e-09\n",
      "-1.1285032681133134e-09\n",
      "-3.432038650059691e-05\n",
      "3.737311010020003e-05\n",
      "-1.8876626364354298e-07\n",
      "-7.604258811409369e-07\n",
      "0.00021606096579742832\n",
      "1.5211317457665017e-06\n",
      "2.8186110433561524e-05\n",
      "9.664909371630277e-08\n",
      "5.8241596364985236e-08\n",
      "-0.0005701270196411026\n",
      "9.194103174449594e-12\n",
      "4.941274335534395e-07\n",
      "0.0\n",
      "7.452252886580208e-07\n",
      "1.377599377664393e-05\n",
      "-2.578917171135477e-05\n",
      "2.958928371031958e-06\n",
      "-1.25412622497565e-06\n",
      "-6.3789070311546566e-12\n",
      "7.700227608856662e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.1645926522041004e-08\n",
      "-0.00011689971354459728\n",
      "1.7422149439763897e-13\n",
      "5.393441645955284e-13\n",
      "-1.7292386780940423e-09\n",
      "3.4061037264632564e-06\n",
      "-1.5029820756966509e-06\n",
      "4.68694875216477e-08\n",
      "1.675860329356259e-12\n",
      "2.4494390050287404e-05\n",
      "-1.8422698154764965e-08\n",
      "1.3576809190400796e-10\n",
      "-3.190080604098612e-12\n",
      "7.326555858920961e-06\n",
      "3.043705091406053e-06\n",
      "-5.659766450035244e-06\n",
      "-2.1535247073767974e-08\n",
      "-2.2542221920931452e-06\n",
      "-8.55495163241924e-05\n",
      "1.7766044164749886e-08\n",
      "-2.52610918127902e-10\n",
      "2.0312566679174653e-08\n",
      "-7.698496521602833e-10\n",
      "0.0\n",
      "0.0\n",
      "1.707024775292628e-07\n",
      "-1.9975716622996254e-10\n",
      "0.0\n",
      "4.378587735411713e-12\n",
      "1.489825911703628e-12\n",
      "8.154017792355845e-07\n",
      "-6.42230608802065e-07\n",
      "1.1508192327616159e-08\n",
      "7.812208327622143e-08\n",
      "2.574308235215448e-07\n",
      "1.4112277684967017e-06\n",
      "-3.108302135492119e-05\n",
      "9.913245976313822e-09\n",
      "0.0\n",
      "3.644119839856624e-05\n",
      "0.0008371087426816446\n",
      "7.302553528876112e-07\n",
      "1.980999749103298e-12\n",
      "-2.053794207937376e-07\n",
      "-7.934838183983476e-08\n",
      "8.139438637594027e-08\n",
      "7.338843044352881e-08\n",
      "-7.311104067895467e-07\n",
      "2.0568199911838577e-09\n",
      "4.616238259814528e-06\n",
      "8.066061469253598e-05\n",
      "-2.164708581106037e-06\n",
      "7.284441016184935e-05\n",
      "-1.7896340401127722e-05\n",
      "-2.495610825955984e-08\n",
      "3.3155746292125785e-07\n",
      "-3.864323544346372e-06\n",
      "-1.595540556681311e-06\n",
      "9.928716431282304e-08\n",
      "1.739487046443783e-05\n",
      "-1.4327875818591707e-05\n",
      "5.100993014718886e-07\n",
      "-3.7190876645517046e-09\n",
      "1.6619853707066097e-06\n",
      "4.0930569536894076e-10\n",
      "-2.1607674183631576e-14\n",
      "-6.688510825533123e-06\n",
      "4.631950687896273e-13\n",
      "-6.728255326114817e-08\n",
      "5.931131764471541e-05\n",
      "-4.075445222309373e-08\n",
      "0.0\n",
      "2.7444823366743446e-06\n",
      "0.0\n",
      "1.033323381149394e-08\n",
      "1.660869911659017e-06\n",
      "7.3437401186327075e-09\n",
      "2.7353534442240947e-09\n",
      "-5.5510800092826893e-05\n",
      "7.606154532138498e-09\n",
      "8.630266280522746e-09\n",
      "-7.530257992621898e-09\n",
      "4.81467648149933e-06\n",
      "-2.6086838272047744e-06\n",
      "3.874404019691261e-05\n",
      "1.779913682251579e-10\n",
      "3.6294951730401742e-06\n",
      "0.0\n",
      "2.741676122008278e-05\n",
      "-3.836873453728274e-06\n",
      "4.1828298588778994e-07\n",
      "4.3844843709279175e-12\n",
      "0.0\n",
      "1.2319901750358237e-08\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.133065898902599e-08\n",
      "-3.886132716757928e-05\n",
      "-2.681971579535339e-10\n",
      "2.7699753548473074e-10\n",
      "1.6467225059601896e-06\n",
      "-1.3869572064919966e-09\n",
      "9.899003424935675e-10\n",
      "1.0755081763841184e-12\n",
      "7.515139449428534e-06\n",
      "1.5671363828432184e-06\n",
      "3.9518156471655274e-07\n",
      "-1.5674937355839238e-06\n",
      "1.432603713356765e-06\n",
      "9.416897280667758e-09\n",
      "0.018829199464318023\n",
      "0.0\n",
      "4.929261076380311e-09\n",
      "3.6401879423331385e-06\n",
      "9.597052189956335e-09\n",
      "9.11718251413984e-05\n",
      "4.088576593055354e-07\n",
      "4.477605433876558e-08\n",
      "0.0\n",
      "2.323086327519846e-07\n",
      "1.593010543631227e-07\n",
      "-6.320107501507092e-08\n",
      "0.00014863811627570937\n",
      "1.5163709830619775e-06\n",
      "3.6658555401509574e-05\n",
      "0.0009014421361423306\n",
      "-2.1843876008578127e-10\n",
      "4.3915328028365275e-07\n",
      "-2.5594355706270487e-11\n",
      "-1.9421388797195605e-07\n",
      "2.8449235208766627e-08\n",
      "7.231366937781061e-11\n",
      "-3.4423871470283595e-09\n",
      "5.645985450044977e-09\n",
      "-0.0020604517776763418\n",
      "3.9732261664256266e-07\n",
      "6.351570136555859e-08\n",
      "-2.8532438947435203e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1335337036392877e-11\n",
      "-1.892142500575542e-05\n",
      "8.814612200424857e-12\n",
      "2.8332779783884404e-13\n",
      "-1.2522413810922215e-07\n",
      "-8.304535289280467e-07\n",
      "0.00011770483313673675\n",
      "-1.8475536786779874e-08\n",
      "9.964275877400469e-14\n",
      "-3.9856941672955886e-11\n",
      "7.251817861041697e-12\n",
      "8.073196651177255e-12\n",
      "0.0\n",
      "4.059602789332532e-10\n",
      "4.950967574717686e-15\n",
      "6.261766415137522e-06\n",
      "-1.6358184383798977e-10\n",
      "-2.556158303491429e-07\n",
      "0.0\n",
      "4.933340665494265e-08\n",
      "3.327608130072933e-11\n",
      "9.786610070974526e-07\n",
      "3.411645146015911e-06\n",
      "3.01617271564443e-07\n",
      "-1.3885048761306414e-05\n",
      "1.596270265919199e-06\n",
      "2.3498622525658383e-11\n",
      "-1.8739675381363253e-07\n",
      "-2.1719687412162645e-09\n",
      "0.0\n",
      "-3.375446742405008e-10\n",
      "-9.097026014056841e-09\n",
      "-3.5918736713219995e-11\n",
      "4.821943988261065e-11\n",
      "1.2690516210134492e-06\n",
      "4.797844313292441e-07\n",
      "2.8708407542300588e-08\n",
      "8.2634534051273e-07\n",
      "6.939154147191631e-11\n",
      "0.0\n",
      "6.06104051338118e-08\n",
      "1.3478974206274267e-06\n",
      "-8.747471670218098e-08\n",
      "1.1168998765727358e-05\n",
      "-4.745998022720001e-06\n",
      "2.3501252354124766e-06\n",
      "-0.00021414900030411\n",
      "1.8105659099676887e-11\n",
      "-6.963518427186105e-07\n",
      "0.0004966436016712547\n",
      "-7.273326263419012e-12\n",
      "6.080178551801719e-09\n",
      "-6.751951468487518e-08\n",
      "2.445600072874582e-06\n",
      "1.3222923646091707e-08\n",
      "-1.2568210097949156e-09\n",
      "-1.4680310142694616e-08\n",
      "9.2635749560992e-06\n",
      "6.943370727499324e-08\n",
      "0.0017545883545994415\n",
      "-0.00034804580240286356\n",
      "7.604047115804165e-07\n",
      "8.794515260101315e-05\n",
      "-2.025563098941414e-06\n",
      "-1.0587256423844877e-08\n",
      "-2.0175352379753422e-09\n",
      "2.4514305716343136e-09\n",
      "2.5958098830234103e-09\n",
      "-6.0202457673584306e-15\n",
      "2.6383676829620476e-09\n",
      "2.6435578080085278e-08\n",
      "3.016654378173179e-08\n",
      "0.006869426296815522\n",
      "2.1939612201416902e-11\n",
      "2.1072195854688172e-09\n",
      "-4.0879027989983586e-11\n",
      "7.275913042589109e-06\n",
      "-2.3833842174999635e-09\n",
      "4.804316248428699e-07\n",
      "1.9088955458581134e-05\n",
      "2.944571781342209e-08\n",
      "9.160600423548647e-06\n",
      "0.00024780204327886626\n",
      "-9.600729717447741e-09\n",
      "1.0179347714452673e-06\n",
      "6.160575845151592e-05\n",
      "2.0699292611176562e-12\n",
      "0.0004654874105376434\n",
      "1.5012043876556629e-09\n",
      "-6.972389741298941e-09\n",
      "5.5684804378209284e-09\n",
      "-1.8587461903434364e-06\n",
      "0.0010018862360640706\n",
      "4.154934267851529e-08\n",
      "-5.346638806771372e-09\n",
      "1.3595351208169949e-08\n",
      "-5.465554050051182e-08\n",
      "-2.0196365829793946e-06\n",
      "-2.140163582202148e-07\n",
      "5.0643686469012985e-15\n",
      "6.491970597541537e-08\n",
      "-2.509946130534436e-09\n",
      "3.7092548895310025e-09\n",
      "1.392415255729706e-08\n",
      "1.9303369701644825e-05\n",
      "-0.00011554908458097211\n",
      "7.080013314806734e-07\n",
      "4.119794798829371e-05\n",
      "5.808668594422303e-07\n",
      "1.451162152846335e-12\n",
      "-1.7372612870645085e-07\n",
      "0.0035417049562445828\n",
      "-1.905345751818961e-06\n",
      "2.7500145795791795e-06\n",
      "0.011978563785270483\n",
      "-0.0006629620253467073\n",
      "1.7337907205932933e-08\n",
      "-3.2742497703607244e-07\n",
      "2.3800493414741213e-05\n",
      "-4.1005668769148456e-07\n",
      "0.00012258188234276282\n",
      "5.73387024475003e-06\n",
      "0.0\n",
      "4.628394724311102e-06\n",
      "7.664563925615315e-09\n",
      "0.00022877984326687324\n",
      "4.1849485350276125e-10\n",
      "-5.135619922257365e-08\n",
      "6.00688449111471e-05\n",
      "-8.043894832647579e-07\n",
      "9.80353508550627e-07\n",
      "3.491196475143238e-11\n",
      "2.7227305618029e-07\n",
      "-5.420398074098799e-07\n",
      "-1.0765902365825038e-05\n",
      "3.469783470163826e-08\n",
      "-2.7442594271570654e-09\n",
      "3.6308868999049855e-05\n",
      "-4.8590362841047804e-17\n",
      "9.542573169936589e-11\n",
      "-2.0054406438087304e-09\n",
      "1.2941481956601402e-10\n",
      "2.4878846798901403e-07\n",
      "2.46116720564965e-05\n",
      "2.143535004240158e-06\n",
      "-3.3281918775792004e-08\n",
      "1.268049949427005e-07\n",
      "4.556508493605074e-14\n",
      "1.13410280243149e-07\n",
      "4.972514365788927e-08\n",
      "3.390073349392823e-09\n",
      "1.144469591231348e-06\n",
      "7.978407503184033e-11\n",
      "-1.4293309154500695e-09\n",
      "4.203290221890743e-06\n",
      "-1.9000468767059862e-10\n",
      "3.8051235484495374e-10\n",
      "-1.7638387825850372e-09\n",
      "0.0008775495966004763\n",
      "-1.3539656293615183e-09\n",
      "5.881973671153081e-06\n",
      "1.0879475056195513e-05\n",
      "7.640706103749957e-07\n",
      "-1.5234569020279593e-06\n",
      "4.442307592241527e-06\n",
      "3.210048877426364e-05\n",
      "4.6092296923201124e-10\n",
      "6.3541834808071905e-06\n",
      "1.0863801436471643e-07\n",
      "3.0898156443432685e-07\n",
      "-1.8013944740439344e-06\n",
      "1.6471958231501412e-05\n",
      "0.0003594985067576557\n",
      "2.080255887896822e-09\n",
      "6.089206504944407e-07\n",
      "0.0002569073378987713\n",
      "-1.1743724893448592e-05\n",
      "-0.0017492155229989986\n",
      "2.8041854836181345e-07\n",
      "1.2673082718138589e-06\n",
      "-4.827953348223647e-06\n",
      "3.344984362558674e-06\n",
      "1.44392240549509e-07\n",
      "2.7611340006679858e-05\n",
      "3.0383406822451124e-05\n",
      "0.0015020080292075992\n",
      "8.626523814798401e-05\n",
      "0.0006317247873537879\n",
      "0.00018238283229398246\n",
      "0.0010160754974542455\n",
      "9.460671651632458e-05\n",
      "6.66505555921355e-06\n",
      "8.991819767125471e-08\n",
      "8.78972491223689e-07\n",
      "6.848199419396068e-11\n",
      "2.567104448767793e-05\n",
      "-8.183880047881966e-06\n",
      "-2.2268170425923188e-05\n",
      "3.788680116705894e-07\n",
      "-2.52321329471727e-06\n",
      "1.7530244766308874e-10\n",
      "1.9586888449586258e-05\n",
      "1.9101920481626317e-05\n",
      "-1.1864856131091472e-08\n",
      "0.0\n",
      "8.401571141349398e-11\n",
      "2.624151476744299e-10\n",
      "1.9316119380436554e-06\n",
      "4.785057458030208e-08\n",
      "1.7166131457055803e-05\n",
      "1.5324670062149607e-07\n",
      "1.6007876038375672e-06\n",
      "-9.171594485022154e-06\n",
      "0.0019594840195462085\n",
      "2.5317659722923203e-10\n",
      "-2.736509160895462e-10\n",
      "9.01085133670965e-14\n",
      "-4.947767045812891e-10\n",
      "4.208106262360978e-07\n",
      "2.4116717324717305e-06\n",
      "-2.739844698416952e-06\n",
      "2.3417786048050013e-09\n",
      "-0.005076395245320013\n",
      "1.8457932481036867e-08\n",
      "1.128579899596904e-08\n",
      "1.9284430684230264e-07\n",
      "0.0\n",
      "2.4079913866620024e-06\n",
      "0.0\n",
      "1.041902238246014e-10\n",
      "-7.467491055770703e-07\n",
      "-5.21054551532874e-09\n",
      "2.936163752598864e-07\n",
      "0.0011380276175059706\n",
      "1.7712033135346467e-06\n",
      "2.236708069468329e-08\n",
      "-2.8546358513630404e-08\n",
      "-5.594687264351634e-10\n",
      "8.670904761819871e-08\n",
      "4.397726292049076e-06\n",
      "3.0771498246270534e-12\n",
      "1.887196895642368e-07\n",
      "1.2136475357966294e-13\n",
      "1.7331253174712116e-11\n",
      "-0.0027036581381872354\n",
      "5.448009734234857e-08\n",
      "5.96471991700262e-09\n",
      "1.981882707210895e-08\n",
      "-1.3558297595457564e-08\n",
      "9.953243909122245e-06\n",
      "-9.551908670935824e-05\n",
      "0.0\n",
      "1.4223539595169356e-06\n",
      "-2.1383757446831224e-08\n",
      "-1.1626815639318202e-08\n",
      "-7.2733335763243875e-06\n",
      "3.6354717078223777e-05\n",
      "9.908730735448905e-07\n",
      "1.6274532399588532e-08\n",
      "0.00010973575287470978\n",
      "2.429570500472923e-09\n",
      "5.0572558361587926e-05\n",
      "0.0010025971785929016\n",
      "4.138223502703378e-11\n",
      "7.553437069479472e-13\n",
      "1.541741864481481e-08\n",
      "3.2474439157262723e-07\n",
      "7.75541176561643e-07\n",
      "1.0451649324970879e-05\n",
      "0.0\n",
      "7.147007021974872e-09\n",
      "1.7962728639951184e-06\n",
      "-1.0981357751333236e-05\n",
      "7.697531301945093e-07\n",
      "6.785305051144454e-10\n",
      "1.5040536412622586e-10\n",
      "-0.002896441219591009\n",
      "7.568339073892936e-05\n",
      "0.0021095627705269857\n",
      "-1.3664619142776262e-07\n",
      "1.0706734998581036e-10\n",
      "2.4071469115559096e-05\n",
      "0.0022609828589263197\n",
      "-2.7382005458775952e-06\n",
      "7.328093719360393e-09\n",
      "-2.637521120667995e-05\n",
      "4.156924747238112e-05\n",
      "0.0004987617591480629\n",
      "0.00039564450967262996\n",
      "0.00018641267762061622\n",
      "-3.334025718276018e-05\n",
      "0.0002125075289965049\n",
      "-0.00045144846806979957\n",
      "4.1858256257332776e-07\n",
      "1.7850365356098177e-06\n",
      "1.5105024013765423e-09\n",
      "-2.8344552543698355e-05\n",
      "0.00011066299143877535\n",
      "3.3894483920467735e-05\n",
      "1.7242183583805054e-05\n",
      "2.762896554435517e-05\n",
      "7.154550726653655e-06\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the csv file\n",
    "df = pd.read_csv('Dynamic_Dataset_v8_without_missing_values.csv', sep=',')\n",
    "\n",
    "x_columns = ['isEntre', # 'Segment_id' 'isQ&A_v2', 'Duration (secs)', 'Ethnicity==White', 'Asked_Amount_USD','Asked_Equity_PCT', \n",
    "    'isQ&A_v2', 'Duration (secs)',\n",
    "    'Age', 'Ethnicity==Black', 'Industry==Children / Education', 'Industry==Fashion / Beauty', 'Industry==Fitness / Sports / Outdoors', \n",
    "    'Industry==Food and Beverage', 'Industry==Health / Wellness / Cleaning', 'Industry==Lifestyle / Home', 'Industry==Software / Tech', 'Industry==Pet Products', \n",
    "    'Revenue_Model==Production/Transactional model', 'Revenue_Model==Subscription model', 'Revenue_Model==Rental or leasing model', 'Retail_Ecommerce==Retail', \n",
    "    'Retail_Ecommerce==Online', 'Has_Patent==YES', 'Has_Patent==IN-PROGRESS', 'Num_of_Presenters', 'Has_Debt', 'Seasonal', 'Num_of_Sales_Last_Year_USD_resc', \n",
    "    'VOICE_pitch', 'VOICE_articulation_rate', 'VOICE_neutral', 'VOICE_calm', 'VOICE_happy', 'VOICE_sad', 'VOICE_angry', \n",
    "    'FACE_smiling', 'FACE_happy', 'FACE_neutral', 'FACE_sad', 'FACE_angry', \n",
    "    'TEXT_financial_sentiment_score', 'TEXT_generic_sentiment_score', 'TEXT_joy', 'TEXT_sadness', 'TEXT_anger', \n",
    "    'TEXT_trust', 'TEXT_conflict', 'TEXT_social_support', 'TEXT_similarity', 'TEXT_respect', 'TEXT_knowledge', 'TEXT_power', 'TEXT_fun',  'TEXT_identity', 'TEXT_romance',\n",
    "    'TEXT_lexical_diversity_mtld', 'TEXT_lexical_sophistication_word_frequency', 'TEXT_num_uncertainty_words_lexicon1',\n",
    "]\n",
    "\n",
    "# Normalize features\n",
    "for col in x_columns:\n",
    "    if col in df:\n",
    "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "### Calculate 2-way Interaction Terms ###\n",
    "# df['inter_2way_1'] = df['VOICE_pitch'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.append('inter_2way_1')\n",
    "# df['inter_2way_2'] = df['VOICE_articulation_rate'] * df['TEXT_sadness']\n",
    "# x_columns.append('inter_2way_2')\n",
    "# df['inter_2way_3'] = df['VOICE_articulation_rate'] * df['TEXT_knowledge']\n",
    "# x_columns.append('inter_2way_3')\n",
    "# df['inter_2way_4'] = df['VOICE_happy'] * df['TEXT_financial_sentiment_score']\n",
    "# x_columns.append('inter_2way_4')\n",
    "# df['inter_2way_5'] = df['VOICE_happy'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.append('inter_2way_5')\n",
    "# df['inter_2way_6'] = df['FACE_sad'] * df['TEXT_conflict']\n",
    "# x_columns.append('inter_2way_6')\n",
    "\n",
    "### Calculate 3-way Interaction Terms ###\n",
    "# df['inter_1a']  = df['VOICE_pitch'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_pitch'] *  df['TEXT_knowledge']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_knowledge']\n",
    "# df['inter_3way_1']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_knowledge']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_1'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_pitch'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_pitch'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_3way_2']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_2'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_pitch'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_pitch'] * df['TEXT_num_uncertainty_words_lexicon1']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_num_uncertainty_words_lexicon1']\n",
    "# df['inter_3way_3']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_num_uncertainty_words_lexicon1']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_3'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_pitch'] * df['FACE_sad']\n",
    "# df['inter_1b']  = df['VOICE_pitch'] * df['TEXT_conflict']\n",
    "# df['inter_1c']  = df['FACE_sad'] * df['TEXT_conflict']\n",
    "# df['inter_3way_4']  = df['VOICE_pitch'] * df['FACE_sad'] * df['TEXT_conflict']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_4'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_pitch'] * df['FACE_sad']\n",
    "# df['inter_1b']  = df['VOICE_pitch'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_1c']  = df['FACE_sad'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_3way_5']  = df['VOICE_pitch'] * df['FACE_sad'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_5'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_smiling']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_financial_sentiment_score']\n",
    "# df['inter_1c']  = df['FACE_smiling'] * df['TEXT_financial_sentiment_score']\n",
    "# df['inter_3way_6']  = df['VOICE_articulation_rate'] * df['FACE_smiling'] * df['TEXT_financial_sentiment_score']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_6'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_smiling']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_1c']  = df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_3way_7']  = df['VOICE_articulation_rate'] * df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_7'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# df['inter_3way_8']  = df['VOICE_articulation_rate'] * df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_8'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_3way_9']  = df['VOICE_articulation_rate'] * df['FACE_happy'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_9'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_neutral']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_power']\n",
    "# df['inter_1c']  = df['FACE_neutral'] * df['TEXT_power']\n",
    "# df['inter_3way_10'] = df['VOICE_articulation_rate'] * df['FACE_neutral'] * df['TEXT_power']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_10'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_sad']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_similarity']\n",
    "# df['inter_1c']  = df['FACE_sad'] * df['TEXT_similarity']\n",
    "# df['inter_3way_11'] = df['VOICE_articulation_rate'] * df['FACE_sad'] * df['TEXT_similarity']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_11'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_articulation_rate'] * df['FACE_angry']\n",
    "# df['inter_1b']  = df['VOICE_articulation_rate'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_1c']  = df['FACE_angry'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_3way_12'] = df['VOICE_articulation_rate'] * df['FACE_angry'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_12'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_happy'] * df['FACE_smiling']\n",
    "# df['inter_1b']  = df['VOICE_happy'] * df['TEXT_generic_sentiment_score']\n",
    "# df['inter_1c']  = df['FACE_smiling'] * df['TEXT_generic_sentiment_score']\n",
    "# df['inter_3way_13'] = df['VOICE_happy'] * df['FACE_smiling'] * df['TEXT_generic_sentiment_score']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_13'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_happy'] * df['FACE_smiling']\n",
    "# df['inter_1b']  = df['VOICE_happy'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_1c']  = df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# df['inter_3way_14'] = df['VOICE_happy'] * df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_14'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_happy'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_happy'] * df['TEXT_social_support']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_social_support']\n",
    "# df['inter_3way_15'] = df['VOICE_happy'] * df['FACE_happy'] * df['TEXT_social_support']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_15'])\n",
    "\n",
    "# df['inter_1a']  = df['VOICE_happy'] * df['FACE_happy']\n",
    "# df['inter_1b']  = df['VOICE_happy'] * df['TEXT_similarity']\n",
    "# df['inter_1c']  = df['FACE_happy'] * df['TEXT_similarity']\n",
    "# df['inter_3way_16'] = df['VOICE_happy'] * df['FACE_happy'] * df['TEXT_similarity']\n",
    "# x_columns.extend(['inter_1a', 'inter_1b', 'inter_1c', 'inter_3way_16'])\n",
    "\n",
    "\n",
    "### Calculate 3-way Interaction Terms ###\n",
    "# df['inter_3way_1']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_knowledge']\n",
    "# x_columns.extend(['inter_3way_1'])\n",
    "\n",
    "# df['inter_3way_2']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_3way_2'])\n",
    "\n",
    "# df['inter_3way_3']  = df['VOICE_pitch'] * df['FACE_happy'] * df['TEXT_num_uncertainty_words_lexicon1']\n",
    "# x_columns.extend(['inter_3way_3'])\n",
    "\n",
    "# df['inter_3way_4']  = df['VOICE_pitch'] * df['FACE_sad'] * df['TEXT_conflict']\n",
    "# x_columns.extend(['inter_3way_4'])\n",
    "\n",
    "# df['inter_3way_5']  = df['VOICE_pitch'] * df['FACE_sad'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_3way_5'])\n",
    "\n",
    "# df['inter_3way_6']  = df['VOICE_articulation_rate'] * df['FACE_smiling'] * df['TEXT_financial_sentiment_score']\n",
    "# x_columns.extend(['inter_3way_6'])\n",
    "\n",
    "# df['inter_3way_7']  = df['VOICE_articulation_rate'] * df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_3way_7'])\n",
    "\n",
    "# df['inter_3way_8']  = df['VOICE_articulation_rate'] * df['FACE_happy'] * df['TEXT_lexical_diversity_mtld']\n",
    "# x_columns.extend(['inter_3way_8'])\n",
    "\n",
    "# df['inter_3way_9']  = df['VOICE_articulation_rate'] * df['FACE_happy'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_3way_9'])\n",
    "\n",
    "# df['inter_3way_10'] = df['VOICE_articulation_rate'] * df['FACE_neutral'] * df['TEXT_power']\n",
    "# x_columns.extend(['inter_3way_10'])\n",
    "\n",
    "# df['inter_3way_11'] = df['VOICE_articulation_rate'] * df['FACE_sad'] * df['TEXT_similarity']\n",
    "# x_columns.extend(['inter_3way_11'])\n",
    "\n",
    "# df['inter_3way_12'] = df['VOICE_articulation_rate'] * df['FACE_angry'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_3way_12'])\n",
    "\n",
    "# df['inter_3way_13'] = df['VOICE_happy'] * df['FACE_smiling'] * df['TEXT_generic_sentiment_score']\n",
    "# x_columns.extend(['inter_3way_13'])\n",
    "\n",
    "# df['inter_3way_14'] = df['VOICE_happy'] * df['FACE_smiling'] * df['TEXT_lexical_sophistication_word_frequency']\n",
    "# x_columns.extend(['inter_3way_14'])\n",
    "\n",
    "# df['inter_3way_15'] = df['VOICE_happy'] * df['FACE_happy'] * df['TEXT_social_support']\n",
    "# x_columns.extend(['inter_3way_15'])\n",
    "\n",
    "df['inter_3way_16'] = df['VOICE_happy'] * df['FACE_happy'] * df['TEXT_similarity']\n",
    "x_columns.extend(['inter_3way_16'])\n",
    "\n",
    "# Group the data by graph id\n",
    "grouped_df = df.groupby('Pitch_id')\n",
    "\n",
    "# Create a list to store the graph data\n",
    "graphs_males = []\n",
    "graphs_females = []\n",
    "\n",
    "# Iterate over the groups\n",
    "for name, group in grouped_df:\n",
    "    # Seperate males and females graphs & Create a PyTorch geometric data object\n",
    "    gender_females = group['Gender==Female'].values[0]\n",
    "    gender_males = group['Gender==Male'].values[0]\n",
    "    \n",
    "    # Extract the node features and labels\n",
    "    x_pd = group[x_columns]\n",
    "    x = x_pd.values    \n",
    "#     print(x_pd.columns)\n",
    "#     break\n",
    "\n",
    "    # Extract the edges between nodes\n",
    "    edges = group[['Segment_id']].T.values[0]\n",
    "    edge_index = torch.tensor([edges[:-1], edges[1:]])\n",
    "    \n",
    "    # Extract the label for each graph\n",
    "    y = group['DV_Received_Offer'].values[0]\n",
    "    \n",
    "    graph = Data(x=torch.tensor(x, dtype=torch.float), y=torch.tensor(y, dtype=torch.long), edge_index=edge_index)\n",
    "    if gender_females == 1:\n",
    "        graphs_females.append(graph)\n",
    "    elif gender_males == 1:\n",
    "        graphs_males.append(graph)\n",
    "    \n",
    "# print('Total graphs for females:', len(graphs_females))\n",
    "# print('Total graphs for males:', len(graphs_males))\n",
    "# # ### Store Graphs ###\n",
    "# # torch.save(graphs_females, 'GNN_data_structure_females_v4_2wayInter.pt')\n",
    "# # torch.save(graphs_males, 'GNN_data_structure_males_v4_2wayInter.pt')\n",
    "# # ### Read Stored Graphs ###\n",
    "# # graphs_females = torch.load('GNN_data_structure_females_v4_2wayInter.pt')\n",
    "# # graphs_males = torch.load('GNN_data_structure_males_v4_2wayInter.pt')\n",
    "\n",
    "num_features = graphs_females[0].x.shape[-1]\n",
    "\n",
    "### Move to GPU ###\n",
    "batch_females = Batch.from_data_list(graphs_females).to(device)\n",
    "batch_males = Batch.from_data_list(graphs_males).to(device)\n",
    "\n",
    "print('Num of features:', num_features)\n",
    "print('Females:', len(graphs_females))\n",
    "print('Males:', len(graphs_males))\n",
    "print('Total:', len(graphs_females)+len(graphs_males))\n",
    "print(len(batch_females.x))\n",
    "print(len(batch_males.x))\n",
    "\n",
    "######################################################\n",
    "### Females - Train Model for Explainable AI ###\n",
    "######################################################\n",
    "print('Females - Train Model for Explainable AI...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "\n",
    "hidden_channels = 128\n",
    "epochs = 150\n",
    "\n",
    "batch_females = Batch.from_data_list(graphs_females).to(device)\n",
    "model_females = train_model(num_features, hidden_channels, epochs, batch_females)\n",
    "\n",
    "print('Finish training model for Females.')\n",
    "\n",
    "######################################################\n",
    "### Males - Train Model for Explainable AI ###\n",
    "######################################################\n",
    "print('Males - Train Model for Explainable AI...')\n",
    "torch.manual_seed(11)\n",
    "torch_geometric.seed_everything(11)\n",
    "np.random.seed(11)\n",
    "\n",
    "hidden_channels = 128\n",
    "epochs = 240\n",
    "\n",
    "batch_males = Batch.from_data_list(graphs_males).to(device)\n",
    "model_males = train_model(num_features, hidden_channels, epochs, batch_males)\n",
    "\n",
    "print('Finish training model for Males.')\n",
    "\n",
    "######################################################\n",
    "### Explainer Captum - Females ###\n",
    "######################################################\n",
    "print('Explanations Females...')\n",
    "feat_import_entre_females = {}\n",
    "feat_import_inves_females = {}\n",
    "pos_i = 0\n",
    "count_graphs = 0\n",
    "\n",
    "for graph in graphs_females:\n",
    "    num_nodes = graph.x.shape[0]\n",
    "    num_feat  = graph.x.shape[1]\n",
    "    batch = Batch.from_data_list([graph]).to(device)\n",
    "    \n",
    "    feat_import_entre_females[count_graphs] = [0]*num_feat\n",
    "    feat_import_inves_females[count_graphs] = [0]*num_feat\n",
    "    count_entre = 0\n",
    "    count_inves = 0\n",
    "    \n",
    "    explainer_females = Explainer(\n",
    "        model = model_females,\n",
    "        algorithm = CaptumExplainer('IntegratedGradients'), # GNNExplainer(epochs=200, lr=0.02),  CaptumExplainer, PGExplainer, AttentionExplainer\n",
    "        explanation_type = \"phenomenon\", # model phenomenon\n",
    "        node_mask_type = \"attributes\", # object common_attributes attributes\n",
    "        model_config=dict(\n",
    "            mode        = \"multiclass_classification\",\n",
    "            task_level  = \"graph\",\n",
    "            return_type = \"log_probs\",\n",
    "        )\n",
    "    )\n",
    "    explanation = explainer_females(\n",
    "        x=batch.x,\n",
    "        edge_index=batch.edge_index,\n",
    "        target=batch.y,\n",
    "        batch=batch.batch\n",
    "    )\n",
    "    explanations_list = explanation['node_mask']\n",
    "    \n",
    "    for i in range(0, num_nodes):\n",
    "        node_features_list = graph.x[i].tolist() # batch.x[pos_i].tolist()\n",
    "        node_importance_list = explanations_list[i].tolist()\n",
    "        isEntre = int(node_features_list[0])\n",
    "        \n",
    "        if isEntre == 1:\n",
    "            count_entre += 1\n",
    "        else:\n",
    "            count_inves += 1\n",
    "        \n",
    "        for j in range(0, num_feat):\n",
    "            if isEntre == 1: # add feature importance to entrepreneurs\n",
    "                feat_import_entre_females[count_graphs][j] += node_importance_list[j]\n",
    "                \n",
    "            else: # add feature importance to investors\n",
    "                feat_import_inves_females[count_graphs][j] += node_importance_list[j]\n",
    "    \n",
    "    if count_inves == 0:\n",
    "        count_inves = 1\n",
    "    feat_import_entre_females[count_graphs] = [x*1.0/count_entre for x in feat_import_entre_females[count_graphs]]\n",
    "    feat_import_inves_females[count_graphs] = [x*1.0/count_inves for x in feat_import_inves_females[count_graphs]]\n",
    "    count_graphs += 1\n",
    "\n",
    "######################################################\n",
    "### Explainer Captum - Males ###\n",
    "######################################################\n",
    "print('Explanations Males...')\n",
    "feat_import_entre_males = {}\n",
    "feat_import_inves_males = {}\n",
    "pos_i = 0\n",
    "count_graphs = 0\n",
    "\n",
    "for graph in graphs_males:\n",
    "    num_nodes = graph.x.shape[0]\n",
    "    num_feat  = graph.x.shape[1]\n",
    "    batch = Batch.from_data_list([graph]).to(device)\n",
    "    \n",
    "    feat_import_entre_males[count_graphs] = [0]*num_feat\n",
    "    feat_import_inves_males[count_graphs] = [0]*num_feat\n",
    "    count_entre = 0\n",
    "    count_inves = 0\n",
    "    \n",
    "    explainer_males = Explainer(\n",
    "        model = model_males,\n",
    "        algorithm = CaptumExplainer('IntegratedGradients'), # GNNExplainer(epochs=200, lr=0.02),  CaptumExplainer, PGExplainer, AttentionExplainer\n",
    "        explanation_type = \"phenomenon\", # model phenomenon\n",
    "        node_mask_type = \"attributes\", # object common_attributes attributes\n",
    "        model_config=dict(\n",
    "            mode        = \"multiclass_classification\",\n",
    "            task_level  = \"graph\",\n",
    "            return_type = \"log_probs\",\n",
    "        )\n",
    "    )\n",
    "    explanation = explainer_males(\n",
    "        x=batch.x,\n",
    "        edge_index=batch.edge_index,\n",
    "        target=batch.y,\n",
    "        batch=batch.batch\n",
    "    )\n",
    "    explanations_list = explanation['node_mask']\n",
    "    \n",
    "    for i in range(0, num_nodes):\n",
    "        node_features_list = graph.x[i].tolist() # batch.x[pos_i].tolist()\n",
    "        node_importance_list = explanations_list[i].tolist()\n",
    "        isEntre = int(node_features_list[0])\n",
    "        \n",
    "        if isEntre == 1:\n",
    "            count_entre += 1\n",
    "        else:\n",
    "            count_inves += 1\n",
    "        \n",
    "        for j in range(0, num_feat):\n",
    "            if isEntre == 1: # add feature importance to entrepreneurs\n",
    "                feat_import_entre_males[count_graphs][j] += node_importance_list[j]\n",
    "                \n",
    "            else: # add feature importance to investors\n",
    "                feat_import_inves_males[count_graphs][j] += node_importance_list[j]\n",
    "    \n",
    "    if count_inves == 0:\n",
    "        count_inves = 1\n",
    "    feat_import_entre_males[count_graphs] = [x*1.0/count_entre for x in feat_import_entre_males[count_graphs]]\n",
    "    feat_import_inves_males[count_graphs] = [x*1.0/count_inves for x in feat_import_inves_males[count_graphs]]\n",
    "    count_graphs += 1\n",
    "\n",
    "print('Finish CAPTUM.')\n",
    "\n",
    "######################################################\n",
    "### Export Importance of Features ###\n",
    "######################################################\n",
    "for i in range(0, len(graphs_females)):\n",
    "    last_item = 0\n",
    "    for elem in feat_import_entre_females[i]:\n",
    "        last_item = str(elem)\n",
    "    print(last_item)\n",
    "for i in range(0, len(graphs_males)):\n",
    "    last_item = 0\n",
    "    for elem in feat_import_entre_males[i]:\n",
    "        last_item = str(elem)\n",
    "    print(last_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369645ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
